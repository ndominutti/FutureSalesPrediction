{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "8tDSdsvTEIwS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "ys58Yk67pAYl"
   },
   "outputs": [],
   "source": [
    "data_path = '..\\\\Data\\\\'\n",
    "# Read all files\n",
    "sales            = pd.read_csv(data_path + 'sales_train.csv')\n",
    "items            = pd.read_csv(data_path + 'items.csv')\n",
    "item_categories  = pd.read_csv(data_path + 'item_categories_translated.csv')\n",
    "shops            = pd.read_csv(data_path + 'shops_translated.csv')\n",
    "test             = pd.read_csv(data_path + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9wBKLbZPBhe3"
   },
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "\n",
    "    '''\n",
    "    Changes column types in the dataframe:  \n",
    "        > 'bool'    type to 'int8'\n",
    "        > 'float64' type to 'float16'\n",
    "        > 'int64'   type to 'int16'\n",
    "    '''\n",
    "\n",
    "    # Select columns to downcast\n",
    "    float_cols = [x for x in df if df[x].dtype == 'float64']\n",
    "    int_cols   = [x for x in df if df[x].dtype == 'int64']\n",
    "    bool_cols  = [x for x in df if df[x].dtype == 'bool']\n",
    "    # Downcast\n",
    "    df[bool_cols] = df[bool_cols].astype(np.int8)\n",
    "    df[float_cols] = df[float_cols].astype(np.float16)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int16)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "decreased-wrestling"
   },
   "source": [
    "### Shop's dataframe preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "recent-writer"
   },
   "outputs": [],
   "source": [
    "shops['city'] = shops['shop_name'].apply(lambda x: x.replace('!','').split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "toxic-dragon"
   },
   "outputs": [],
   "source": [
    "# Encoding our city feature\n",
    "label_encoder = LabelEncoder()\n",
    "shops['city'] = label_encoder.fit_transform(shops['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mechanical-defendant"
   },
   "source": [
    "### Item's dataframe preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "patient-performance"
   },
   "outputs": [],
   "source": [
    "# Create a feature with the 1st-ever-sale date for every item\n",
    "items['first_sale_date'] = sales.groupby('item_id').agg({'date_block_num': 'min'})['date_block_num']\n",
    "items['first_sale_date'] = items['first_sale_date'].fillna(34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "consecutive-plumbing"
   },
   "source": [
    "### Item_categories' dataframe preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "conscious-volume"
   },
   "outputs": [],
   "source": [
    "# Create a major feature\n",
    "item_categories['major'] = item_categories['item_category_name'].apply(lambda x: x.split()[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "forbidden-promotion"
   },
   "outputs": [],
   "source": [
    "# Replace with 'etc' if category count is less than 5\n",
    "item_categories['major'] = item_categories['major'].apply(lambda x: x if len(item_categories[item_categories['major']==x]) >= 5 else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "powered-paraguay"
   },
   "outputs": [],
   "source": [
    "# Encoding our major variable\n",
    "label_encoder = LabelEncoder()\n",
    "item_categories['major'] = label_encoder.fit_transform(item_categories['major'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exotic-newport"
   },
   "source": [
    "### Sale's dataframe preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "parallel-accent"
   },
   "outputs": [],
   "source": [
    "# Outliers removal\n",
    "sales = sales[(sales['item_price'] > 0) & (sales['item_price'] < 50000)]\n",
    "sales = sales[(sales['item_cnt_day'] > 0) & (sales['item_cnt_day'] < 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1622731269575,
     "user": {
      "displayName": "Nico Dominutti",
      "photoUrl": "",
      "userId": "09261720198340163845"
     },
     "user_tz": 180
    },
    "id": "engaging-ethernet",
    "outputId": "50e72521-f01b-4854-836f-68d6cb01c82e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0 (id: ! Yakutsk Ordzhonikidze, 56 fran)         <--->  57 (id: Yakutsk Ordzhonikidze, 56)\n",
      "> 1 (id: ! Yakutsk shopping center \"Central\" Fran) <--->  58 (id: Yakutsk shopping center \"Central\")\n",
      "> 10 (id: Zhukovsky st. Chkalova 39m?)             <--->  11 (id: Zhukovsky st. Chkalova 39m²)\n",
      "> 39 (id: Rostnone TRK \"Megacentr Horizont\")       <--->  40 (id: Rostov on the Don TRK \"Megcenter Horizon\" island)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As we saw on EDA some shops are duplicated w/distinct shop_id and shop_name\n",
    "print(f'> {shops.iloc[0,0]} (id: {shops.iloc[0,1]})         <--->  \\\n",
    "{shops.iloc[57,0]} (id: {shops.iloc[57,1]})\\n\\\n",
    "> {shops.iloc[1,0]} (id: {shops.iloc[1,1]}) <--->  \\\n",
    "{shops.iloc[58,0]} (id: {shops.iloc[58,1]})\\n\\\n",
    "> {shops.iloc[10,0]} (id: {shops.iloc[10,1]})             <--->  \\\n",
    "{shops.iloc[11,0]} (id: {shops.iloc[11,1]})\\n\\\n",
    "> {shops.iloc[39,0]} (id: {shops.iloc[39,1]})       <--->  \\\n",
    "{shops.iloc[40,0]} (id: {shops.iloc[40,1]})\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "religious-manual"
   },
   "outputs": [],
   "source": [
    "# We correct this cases\n",
    "sales['shop_id'] = sales['shop_id'].replace({0: 57, 1: 58, 11: 10, 40: 39})\n",
    "test['shop_id'] = test['shop_id'].replace({0: 57, 1: 58, 11: 10, 40: 39})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "automatic-clause"
   },
   "outputs": [],
   "source": [
    "# Some of the shops that are in the sales dataframe are not in the Test set. \n",
    "# We Leak to improve predictions\n",
    "shops_on_test = test['shop_id'].unique()\n",
    "sales = sales[sales['shop_id'].isin(shops_on_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "complicated-fighter"
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TteBfOHtihTE"
   },
   "source": [
    "As seen in the EDA, Test set is a result of all posible combinations of shops + items for a given month (a cartesian product), we'll mimic that approach in our train set for every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "hAwFdXsxvhro"
   },
   "outputs": [],
   "source": [
    "index_cols = ['date_block_num','shop_id', 'item_id']\n",
    "\n",
    "# We get the cartesian product for every month in the train set\n",
    "combinations = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops     = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items     = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    combinations.append(np.array(list(product([block_num],cur_shops, cur_items))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "uE7YYHsSvkmP"
   },
   "outputs": [],
   "source": [
    "# Turn the combinations into a pandas dataframe\n",
    "combinations = pd.DataFrame(np.vstack(combinations), columns = index_cols)\n",
    "\n",
    "# Generate aggregated features on item_cnt_day and item_price\n",
    "gb = sales.groupby(index_cols).agg({'item_cnt_day':'sum', 'item_price':'mean'})\n",
    "gb = gb.reset_index()\n",
    "gb.rename(columns={'item_cnt_day':'item_cnt_month',\\\n",
    "                   'item_price':'item_price_mean'}, inplace=True)\n",
    "\n",
    "# Join the data to the combinations\n",
    "df = pd.merge(combinations,gb,how='left',on=index_cols)\n",
    "\n",
    "# Generate a feature for the number of items sold\n",
    "gb = sales.groupby(index_cols).agg({'item_cnt_day': 'count'})\n",
    "gb = gb.reset_index()\n",
    "gb = gb.rename(columns={'item_cnt_day': 'item_count'})\n",
    "\n",
    "df = pd.merge(df, gb, on=index_cols, how='left')\n",
    "\n",
    "\n",
    "del combinations, gb, sales\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "later-substitute"
   },
   "source": [
    "### Consolidate a full Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "champion-trust"
   },
   "outputs": [],
   "source": [
    "# Lets append to the DF the Test data\n",
    "test['date_block_num'] = 34\n",
    "df = pd.concat([df, test.drop('ID',axis=1)], ignore_index=True,\\\n",
    "               keys=index_cols)\n",
    "df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "acting-courage"
   },
   "outputs": [],
   "source": [
    "shops.drop(['shop_name','Unnamed: 0'],axis=1,inplace=True)\n",
    "item_categories.drop(['item_category_name','Unnamed: 0'],axis=1,inplace=True)\n",
    "items.drop(['item_name'],axis=1,inplace=True)\n",
    "\n",
    "# get the final merged df\n",
    "df = df.merge(shops, on='shop_id', how='left')\n",
    "df = df.merge(items, on='item_id', how='left')\n",
    "df = df.merge(item_categories, on='item_category_id', how='left')\n",
    "\n",
    "\n",
    "df = downcast(df)\n",
    "\n",
    "del shops, items, item_categories\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "young-freeze"
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "legitimate-pendant"
   },
   "source": [
    "### Mean Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "t5Ldr6Bmxrb5"
   },
   "outputs": [],
   "source": [
    "def mean_encodings(df, features):\n",
    "\n",
    "    '''\n",
    "    Create mean encodings on item_cnt_month based on the features passed\n",
    "    '''\n",
    "\n",
    "    temporal = df.groupby(features).agg({'item_cnt_month': 'mean'})\n",
    "    temporal.reset_index(inplace=True)\n",
    "    names = features + ['mean_sales']\n",
    "    temporal.rename(columns={'item_cnt_month':'_'.join(names)}, inplace=True)\n",
    "\n",
    "    #Mege with the dataset\n",
    "    df = pd.merge(df, temporal, on=features, how='left')\n",
    "    df = downcast(df)\n",
    "\n",
    "    del temporal\n",
    "    gc.collect();\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "kQro8bKxyDV9"
   },
   "outputs": [],
   "source": [
    "df = mean_encodings(df,['date_block_num','item_id'])\n",
    "df = mean_encodings(df,['date_block_num','item_id','city'])\n",
    "df = mean_encodings(df,['date_block_num','shop_id','item_category_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cutting-sherman"
   },
   "source": [
    "### Create Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Va9qEGiPXvRN"
   },
   "outputs": [],
   "source": [
    "def lag_features(df, index_features,lag_feature):\n",
    "\n",
    "    '''\n",
    "    Create lag features for -1,-2,-3 months on the index_features passed\n",
    "    '''\n",
    "\n",
    "    df_temp = df[index_features + [lag_feature]].copy() \n",
    "\n",
    "    # Create lag features\n",
    "    for month in range(1, 4):\n",
    "        lag_name = lag_feature +'_lag' + str(month)\n",
    "        df_temp.columns = index_features + [lag_name]\n",
    "\n",
    "        # Add 1 to date_block_num to merge df_temp with the passed df\n",
    "        df_temp['date_block_num'] += month\n",
    "\n",
    "        # Merge df with df_temp based on idx_feature\n",
    "        df = df.merge(df_temp.drop_duplicates(),on=index_features,how='left')\n",
    "\n",
    "        # Fillna with 0 \n",
    "        df[lag_name] = df[lag_name].fillna(0)\n",
    "\n",
    "        df = downcast(df)\n",
    "\n",
    "\n",
    "    del df_temp\n",
    "    gc.collect()\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "SqNU67gTX6iK"
   },
   "outputs": [],
   "source": [
    "#Features to lag\n",
    "features = ['item_price_mean','item_cnt_month','item_count', 'date_block_num_item_id_mean_sales',\\\n",
    "                                                                  'date_block_num_item_id_city_mean_sales']\n",
    "\n",
    "for feat in features:\n",
    "    df = lag_features(df, ['date_block_num', 'shop_id', 'item_id'], feat)\n",
    "\n",
    "df = lag_features(df, ['date_block_num', 'shop_id', 'item_category_id'],\n",
    "      'date_block_num_shop_id_item_category_id_mean_sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "occupied-slave"
   },
   "outputs": [],
   "source": [
    "# Remove data from the first 2 months as they will have no lagged data\n",
    "df = df.drop(df[df['date_block_num'] < 3].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "remarkable-aruba"
   },
   "source": [
    "### Final Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "limited-skiing"
   },
   "outputs": [],
   "source": [
    "# Generate item_cnt_month mean from the last 3 months \n",
    "df['3_Months_Mean'] = df[['item_cnt_month_lag1', 'item_cnt_month_lag2', 'item_cnt_month_lag3']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVMgpPuY4CNY"
   },
   "source": [
    "As we saw in the EDA file, the distribution from the Train set shows that the item_cnt_day is concentrated arround in the range [0,20]<br>\n",
    "> We are going to clip this values respecting this insight (increasing our prediction score +10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "purple-giving"
   },
   "outputs": [],
   "source": [
    "clip = ['item_cnt_month', 'item_cnt_month_lag1',\n",
    "       'item_cnt_month_lag2', 'item_cnt_month_lag3', 'item_count_lag1',\n",
    "       'item_count_lag2', 'item_count_lag3',\n",
    "       'date_block_num_item_id_mean_sales_lag1',\n",
    "       'date_block_num_item_id_mean_sales_lag2',\n",
    "       'date_block_num_item_id_mean_sales_lag3',\n",
    "       'date_block_num_item_id_city_mean_sales_lag1',\n",
    "       'date_block_num_item_id_city_mean_sales_lag2',\n",
    "       'date_block_num_item_id_city_mean_sales_lag3',\n",
    "       'date_block_num_shop_id_item_category_id_mean_sales_lag1',\n",
    "       'date_block_num_shop_id_item_category_id_mean_sales_lag2',\n",
    "       'date_block_num_shop_id_item_category_id_mean_sales_lag3','3_Months_Mean']\n",
    "\n",
    "for col in clip:\n",
    "    df[col] = df[col].clip(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "contrary-military"
   },
   "outputs": [],
   "source": [
    "# Generate percentage evolution from month to month\n",
    "df['evolution_1'] = df['item_cnt_month_lag1']/df['item_cnt_month_lag2']\n",
    "df['evolution_1'] = df['evolution_1'].replace([np.inf, -np.inf],np.nan).fillna(0)\n",
    "df['evolution_2'] = df['item_cnt_month_lag2']/df['item_cnt_month_lag3']\n",
    "df['evolution_2'] = df['evolution_2'].replace([np.inf, -np.inf],np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "empirical-observation"
   },
   "outputs": [],
   "source": [
    "# Generate a binary future for the first_month of every item\n",
    "df['first_month'] = df['first_sale_date'] == df['date_block_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "published-satin"
   },
   "outputs": [],
   "source": [
    "# Generate a permanence feature\n",
    "df['permanence'] = df['date_block_num'] - df['first_sale_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "nominated-viewer"
   },
   "outputs": [],
   "source": [
    "# Generate the n° of month of every instance\n",
    "df['month'] = df['date_block_num']%12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "prospective-treaty"
   },
   "outputs": [],
   "source": [
    "# Drop the columns from that bring data from the current month and make final\n",
    "# dataframe preprocessing\n",
    "toDrop = ['item_price_mean', 'item_count',\\\n",
    "          'date_block_num_shop_id_item_category_id_mean_sales',\\\n",
    "          'date_block_num_item_id_city_mean_sales',\\\n",
    "          'date_block_num_item_id_mean_sales','first_sale_date']\n",
    "\n",
    "df.drop(toDrop, axis=1, inplace=True)\n",
    "df = downcast(df)\n",
    "df.rename(columns={'item_cnt_month':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "2f6QfxISq6qe"
   },
   "outputs": [],
   "source": [
    "df.to_pickle(data_path + 'df_processed.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1200.029073,
   "end_time": "2021-04-29T12:14:19.218135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-29T11:54:19.189062",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
